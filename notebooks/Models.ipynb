{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for dataviz\n",
    "import plotly.express as px\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objects as go\n",
    "import cufflinks as cf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration for plotly\n",
    "template = \"plotly_dark\"\n",
    "\n",
    "# offline configuration of cufflinks\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('../data/clean.csv')\n",
    "\n",
    "with open('../data/meta_data.json') as json_file:\n",
    "    meta = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['y']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modification des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Discretisation de Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le prof veut qu'on fasse de la clssification et pas de la regression, il faut choisir les categories de la variable Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data, x = meta['y'], marginal=\"box\", template = template).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut couper selon le 1er quartil et la moyenne. Cela permet de distribuer les valeurs de manière à peu près homogène. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = pd.cut(data[meta['y']], bins=[0, 95, 98, 100], labels=['bad', 'good', 'excellent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_cat.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[meta['y']] = y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Traitement des donnees geospatiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les donnees geospatiales, on propose de diviser les quartiers (neighbourhoods_cleansed) en trois categories (good, neutral, bad). On preconise que le l'indicateur qui aura le plus grand impact sur la perception de la qualité des appartements, directement et indirectement, sera le taux de criminalite dans le quartier. Donnees tirees de https://www.areavibes.com/san+francisco-ca/crime/\n",
    "\n",
    "Selon le score de criminalite de chaque quartier, attribue un score 0, 1, 2.\n",
    "\n",
    "F a D- : 0\n",
    "D a B- : 1\n",
    "B a A+ : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des donnees sur une carte :\n",
    "\n",
    "\n",
    "Box = (data.longitude.min(),   data.longitude.max(),      \n",
    "        data.latitude.min(), data.latitude.max())\n",
    "    \n",
    "#Box = (-122.5149, -122.3571,      \n",
    "#       37.7083, 37.8111)\n",
    "\n",
    "carte = plt.imread(\"../data/map.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20,20))\n",
    "ax.scatter(data.longitude, data.latitude, zorder=1, alpha= 0.2, c='fuchsia', s=10)\n",
    "ax.set_title('Plotting Spatial Data on SF Map')\n",
    "ax.set_xlim(Box[0],Box[1])\n",
    "ax.set_ylim(Box[2],Box[3])\n",
    "ax.imshow(carte, zorder=0, extent = Box, aspect= 'equal')\n",
    "\n",
    "#fig.savefig('testeo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Traitement des variables categoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['property_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['property_type'] = data['property_type'].replace(['Serviced apartment', 'Loft'], 'Apartment')\n",
    "\n",
    "data['property_type'] = data['property_type'].replace(['Boutique hotel', 'Hostel','Aparthotel'], 'Hotel')\n",
    "\n",
    "data['property_type'] = data['property_type'].replace(['Townhouse', 'Guesthouse', 'Villa'], 'House')\n",
    "\n",
    "data['property_type'] = data['property_type'].replace(['Bed and breakfast'], 'Guest suite')\n",
    "\n",
    "data['property_type'] = data['property_type'].replace(['Bungalow', 'Cottage', 'Earth house', 'Cabin', 'In-law',\n",
    "                                       'Dome house', 'Resort', 'Castle', 'Tiny house'], 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut verifier les categories que j'ai crée, j'ai des doutes sur certains regroupements, comme par exemple pour **Loft, Aparthotel, ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['city'] = data['city'].replace(['San Francisco, Hayes Valley', 'Noe Valley - San Francisco', \n",
    "                                     'San Francisco ', 'Brisbane'], 'San Francisco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Separation entrainement/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# separate target from predictors\n",
    "y = data[meta['y']]\n",
    "X = data.drop(columns = meta['y'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = [\"excellent\", \"bad\", \"good\"],\n",
    "    y = y_train.value_counts(),\n",
    "    name = 'train',\n",
    "    #marker_color = 'indianred',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = [\"excellent\", \"bad\", \"good\"],\n",
    "    y = y_valid.value_counts(),\n",
    "    name = 'validation',\n",
    "    #marker_color = 'lightsalmon',\n",
    "))\n",
    "\n",
    "# Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "#fig.update_layout(barmode='group', xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print()\n",
    "print(y_valid.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que les classes sont à peu pres bien reparties dans les ensembles \"train\" et \"validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing et entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "### Trie à faire dans les imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Etudier les SimpleImputer\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Preprocessing for boolean data\n",
    "# boolean_transformer = OrdinalEncoder()\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, meta['quant']),\n",
    "        ('cat', categorical_transformer, meta['cat'] + meta['bool'])\n",
    "        #('bool'), boolean_transformer, meta['bool']\n",
    "    ])\n",
    "\n",
    "label = meta['quant'] + meta['cat'] + meta['bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model_tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model_rf)\n",
    "                         ])\n",
    "\n",
    "clf_tree = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model_tree)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Etude des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "clf_rf.fit(X_train, y_train)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds_rf = clf_rf.predict(X_valid)\n",
    "preds_tree = clf_tree.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(name, y_valid, preds):\n",
    "    \n",
    "    label = [\"bad\", \"good\", \"excellent\"]\n",
    "    label_r = label.copy()\n",
    "    label_r.reverse()\n",
    "    \n",
    "    # precision\n",
    "    print(\"Accuracy\", name, \":\", metrics.accuracy_score(y_valid, preds),\"\\n\")\n",
    "\n",
    "    # matrice de confusion\n",
    "    m = metrics.confusion_matrix(y_valid, preds, labels = label)\n",
    "    #print(\"Confusion matrix\", name, \":\\n%s\" % m)\n",
    "    \n",
    "    # heatmap\n",
    "    h = []\n",
    "    for elt in reversed(m):\n",
    "        h.append(elt)\n",
    "    \n",
    "    go.Figure(data=go.Heatmap(\n",
    "                       z = h,\n",
    "                       x = label,\n",
    "                       y = label_r,\n",
    "                       colorscale = \"oryel\")\n",
    "             ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Accuracy et matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_results(\"random forest\", y_valid, preds_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_results(\"classification tree\", y_valid, preds_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Importance des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etude de l'importance des variables\n",
    "imp_tree = clf_tree.steps[1][1].feature_importances_\n",
    "imp_rf = clf_rf.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = imp_tree,\n",
    "    y = label,\n",
    "    name = 'tree',\n",
    "    orientation = 'h'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = imp_rf,\n",
    "    y = label,\n",
    "    name = 'random forest',\n",
    "    orientation = 'h'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    #autosize = True,\n",
    "    # width=500,\n",
    "    height = 1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inutile : ne pas executer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "import pydot \n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "iris = load_iris()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "\n",
    "dot_data = StringIO() \n",
    "tree.export_graphviz(clf, out_file = dot_data) \n",
    "#tree.export_graphviz(clf_tree, out_file = dot_data) \n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph[0].write_pdf(\"C:\\Users\\Florent Glauda\\Documents\\Poly\\IND6212 - Exploration de données industrielles\\IND6212\\iris.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant') # Your code here\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "]) # Your code here\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=0) # Your code here\n",
    "\n",
    "# Check your answer\n",
    "step_1.a.check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
