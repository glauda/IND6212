{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for dataviz\n",
    "import plotly.express as px\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objects as go\n",
    "import cufflinks as cf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offline configuration of cufflinks\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('../data/clean.csv')\n",
    "\n",
    "with open('../data/meta_data.json') as json_file:\n",
    "    meta = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['y']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modification des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Discretisation de Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le prof veut qu'on fasse de la clssification et pas de la regression, il faut choisir les categories de la variable Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data, x = meta['y'], marginal=\"box\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut couper selon le 1er quartil et la moyenne. Cela permet de distribuer les valeurs de manière à peu près homogène. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = pd.cut(data[meta['y']], bins=[0, 95, 98, 100], labels=['bad', 'good', 'excellent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_cat.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[meta['y']] = y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Traitement des donnees geospatiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les donnees geospatiales, on propose de diviser les quartiers (neighbourhoods_cleansed) en trois categories (good, neutral, bad). On preconise que le l'indicateur qui aura le plus grand impact sur la perception de la qualité des appartements, directement et indirectement, sera le taux de criminalite dans le quartier. Donnees tirees de https://www.areavibes.com/san+francisco-ca/crime/\n",
    "\n",
    "Selon le score de criminalite de chaque quartier, attribue un score 0, 1, 2.\n",
    "\n",
    "F a D- : 2\n",
    "D a B- : 1\n",
    "B a A+ : 0\n",
    "\n",
    "On ajoute une colonne 'crime' aux données, qui attribue ce score 0/1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajout d'une colonne 'crime'\n",
    "\n",
    "neighbourhood_crime=[['Bayview', 'Bernal Heights', 'Castro/Upper Market', 'Chinatown', 'Diamond Heights', 'Downtown/Civic Center','Haight Ashbury','Lakeshore', 'Marina', 'Mission', 'Nob Hill', 'Outer Mission', 'Potrero Hill', 'Russian Hill', 'South of Market', 'Visitacion Valley', 'Western Addition'],\n",
    "                     ['Excelsior', 'Financial District', 'Golden Gate Park', 'Glen Park', 'Inner Richmond', 'North Beach', 'Pacific Heights', 'Parkside', 'Presidio Heights', 'Seacliff', 'Twin Peaks', 'West of Twin Peaks'],\n",
    "                     ['Crocker Amazon', 'Inner Sunset', 'Noe Valley', 'Ocean View', 'Outer Richmond', 'Outer Sunset', 'Treasure Island/YBI']]\n",
    "\n",
    "data['crime'] = float('nan')\n",
    "crime_color = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remplissage de la colonne 'crime'\n",
    "\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    if data['neighbourhood_cleansed'][i] in neighbourhood_crime[0]:\n",
    "        data['crime'][i] = 2\n",
    "        crime_color.append('maroon')\n",
    "    \n",
    "    elif data['neighbourhood_cleansed'][i] in neighbourhood_crime[1]:\n",
    "        data['crime'][i] = 1\n",
    "        crime_color.append('darkorange')\n",
    "    \n",
    "    elif data['neighbourhood_cleansed'][i] in neighbourhood_crime[2]:\n",
    "        data['crime'][i] = 0\n",
    "        crime_color.append('orangered')\n",
    "    \n",
    "    else:\n",
    "        #print('review neighbourhood_crime for missing neighbourhoods')\n",
    "        crime_color.append('grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des donnees sur une carte :\n",
    "\n",
    "\n",
    "#Box = (data.longitude.min(),   data.longitude.max(),      \n",
    "#        data.latitude.min(), data.latitude.max())\n",
    "    \n",
    "Box = (-122.5132, -122.3686,      \n",
    "       37.7045, 37.8290)\n",
    "\n",
    "carte = plt.imread(\"../data/map.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (11.48,12.48))\n",
    "ax.scatter(data.longitude, data.latitude, zorder=1, alpha= 1, c=crime_color, s=10)\n",
    "#ax.scatter(data.longitude, data.latitude, zorder=1, alpha= 1, c='fuchsia', s=10)\n",
    "ax.set_title('Plotting Spatial Data on SF Map')\n",
    "ax.set_xlim(Box[0],Box[1])\n",
    "ax.set_ylim(Box[2],Box[3])\n",
    "ax.imshow(carte, zorder=0, extent = Box, aspect= 'equal')\n",
    "\n",
    "#fig.savefig('testeo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Traitement des variables categoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['property_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['property_type'] = data['property_type'].replace(['Serviced apartment', 'Loft'], 'Apartment')\n",
    "\n",
    "data['property_type'] = data['property_type'].replace(['Boutique hotel', 'Hostel','Aparthotel'], 'Hotel')\n",
    "\n",
    "data['property_type'] = data['property_type'].replace(['Townhouse', 'Guesthouse', 'Villa'], 'House')\n",
    "\n",
    "data['property_type'] = data['property_type'].replace(['Bed and breakfast'], 'Guest suite')\n",
    "\n",
    "data['property_type'] = data['property_type'].replace(['Bungalow', 'Cottage', 'Earth house', 'Cabin', 'In-law',\n",
    "                                       'Dome house', 'Resort', 'Castle', 'Tiny house'], 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut verifier les categories que j'ai crée, j'ai des doutes sur certains regroupements, comme par exemple pour **Loft, Aparthotel, ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['city'] = data['city'].replace(['San Francisco, Hayes Valley', 'Noe Valley - San Francisco', \n",
    "                                     'San Francisco ', 'Brisbane'], 'San Francisco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['crime'].isna().sum())\n",
    "data['crime'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"name\"] + \" \" + data[\"summary\"]\n",
    "\n",
    "for var in meta[\"text\"]:\n",
    "    data[var] = data[var].replace(np.nan, \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"name\"] = data[\"name\"] + \" \" + data[\"summary\"] + \" \" + data[\"space\"] + \" \" + data[\"description\"]\n",
    "\n",
    "data[\"neighborhood_overview\"] = data[\"neighborhood_overview\"] + \" \" + data[\"notes\"] + \" \" + data[\"interaction\"] + \" \" + data[\"house_rules\"] + \" \" + data[\"host_about\"]\n",
    "\n",
    "data[\"transit\"] = data[\"transit\"] + \" \" + data[\"access\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['summary', 'space', 'description', 'notes', 'interaction', 'house_rules', 'host_about', 'access'], axis=1)\n",
    "\n",
    "data = data.rename(columns={\"name\": \"housing_description\", \"neighborhood_overview\": \"context_description\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Separation entrainement/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# separate target from predictors\n",
    "y = data[meta['y']]\n",
    "X = data.drop(columns = meta['y'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = [\"excellent\", \"bad\", \"good\"],\n",
    "    y = y_train.value_counts(),\n",
    "    name = 'train',\n",
    "    #marker_color = 'indianred',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = [\"excellent\", \"bad\", \"good\"],\n",
    "    y = y_valid.value_counts(),\n",
    "    name = 'validation',\n",
    "    #marker_color = 'lightsalmon',\n",
    "))\n",
    "\n",
    "# Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "#fig.update_layout(barmode='group', xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print()\n",
    "print(y_valid.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que les classes sont à peu pres bien reparties dans les ensembles \"train\" et \"validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Données textuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.stem import LancasterStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()\n",
    "\n",
    "def tokenize(text):\n",
    "        return [stemmer.stem(re.sub(r'\\d+', '', word).translate(str.maketrans('', '', string.punctuation))) for word in nltk.word_tokenize(text) if len(word) > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_text = [\"housing_description\", \"context_description\", \"transit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for var in var_text:\n",
    "    \n",
    "    # On construit la matrice terme-document avec la ponderation TF-IDF. On note le vocabulaire obtenu\n",
    "    vectorizer = TfidfVectorizer(lowercase = True,\n",
    "                             stop_words = 'english',\n",
    "                             min_df = 200,\n",
    "                             tokenizer = tokenize\n",
    "                            )\n",
    "\n",
    "    td = vectorizer.fit_transform(X_train[var])\n",
    "    voc = vectorizer.get_feature_names()\n",
    "    \n",
    "    print(voc)\n",
    "    \n",
    "    # On crée des clusters sur la matrice terme-document. On remplace chaque document par son numero de cluster \n",
    "    kmeans = KMeans(n_clusters=5, init = 'random', random_state=0).fit( preprocessing.scale(td.todense()) )\n",
    "    X_train[var] = kmeans.predict( preprocessing.scale(td.todense()) )\n",
    "    \n",
    "    # Pour l'ensemble de validation, on crée ensuite la matrice terme-document avec le vocabulaire precedent\n",
    "    new_vectorizer = TfidfVectorizer(lowercase = True,\n",
    "                             tokenizer = tokenize,\n",
    "                             vocabulary = voc)\n",
    "\n",
    "    # On regarde ensuite dans quel cluster tombe chaque document\n",
    "    new_td = new_vectorizer.fit_transform(X_valid[var])\n",
    "    X_valid[var] = kmeans.predict( preprocessing.scale(new_td.todense()) )\n",
    "    \n",
    "    print( var + \" : done\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing et entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "### Trie à faire dans les imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Etudier les SimpleImputer\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder())\n",
    "    #('label', LabelEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, meta['quant'] + meta['date']),\n",
    "        #('cat', categorical_transformer, meta['cat'] + meta['bool'] + ['crime'])\n",
    "        ('cat', categorical_transformer, meta['cat'] + meta['bool'] + ['crime'] + var_text)\n",
    "    ])\n",
    "\n",
    "label = meta['quant'] + meta['date'] + meta['cat'] + meta['bool'] + ['crime'] + var_text\n",
    "#label = meta['quant'] + meta['date'] + meta['cat'] + meta['bool'] + ['crime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model_tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model_rf)\n",
    "                         ])\n",
    "\n",
    "clf_tree = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model_tree)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Etude des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "clf_rf.fit(X_train, y_train)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds_rf = clf_rf.predict(X_valid)\n",
    "preds_tree = clf_tree.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "def show_results(name, y_valid, preds):\n",
    "    \n",
    "    label = [\"bad\", \"good\", \"excellent\"]\n",
    "    label_r = label.copy()\n",
    "    label_r.reverse()\n",
    "    \n",
    "    # precision\n",
    "    print(\"Accuracy\", name, \":\", metrics.accuracy_score(y_valid, preds),\"\\n\")\n",
    "\n",
    "    # matrice de confusion\n",
    "    m = metrics.confusion_matrix(y_valid, preds, labels = label)\n",
    "    #print(\"Confusion matrix\", name, \":\\n%s\" % m)\n",
    "    \n",
    "    # heatmap\n",
    "    h = []\n",
    "    for elt in reversed(m):\n",
    "        h.append(elt)\n",
    "    \n",
    "    ff.create_annotated_heatmap(\n",
    "            z = h,\n",
    "            x = label,\n",
    "            y = label_r,\n",
    "            colorscale = \"oryel\"\n",
    "        ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Accuracy et matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_results(\"random forest\", y_valid, preds_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_results(\"classification tree\", y_valid, preds_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Importance des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etude de l'importance des variables\n",
    "imp_tree = clf_tree.steps[1][1].feature_importances_\n",
    "imp_rf = clf_rf.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = imp_tree,\n",
    "    y = label,\n",
    "    name = 'tree',\n",
    "    orientation = 'h'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = imp_rf,\n",
    "    y = label,\n",
    "    name = 'random forest',\n",
    "    orientation = 'h'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    #autosize = True,\n",
    "    # width=500,\n",
    "    height = 1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Affichage de l'arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,20))\n",
    "a = plot_tree(clf_tree[1], \n",
    "              feature_names = label, \n",
    "              filled = True, \n",
    "              rounded = True, \n",
    "              fontsize = 14,\n",
    "              max_depth=5,\n",
    "              impurity = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value : [ bad, excellent, good ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_print = X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_print.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = []\n",
    "\n",
    "for row in data_to_print.itertuples(index=False):\n",
    "    \n",
    "    if row.review_scores_rating == \"excellent\":\n",
    "        color.append('maroon')\n",
    "        \n",
    "    elif row.review_scores_rating == \"good\":\n",
    "        color.append('darkorange')\n",
    "        \n",
    "    elif row.review_scores_rating == \"bad\":\n",
    "        color.append('orangered')\n",
    "    \n",
    "    else:\n",
    "        #print('review neighbourhood_crime for missing neighbourhoods')\n",
    "        color.append('grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des donnees sur une carte :\n",
    "\n",
    "\n",
    "#Box = (data.longitude.min(),   data.longitude.max(),      \n",
    "#        data.latitude.min(), data.latitude.max())\n",
    "    \n",
    "Box = (-122.5132, -122.3686,      \n",
    "       37.7045, 37.8290)\n",
    "\n",
    "carte = plt.imread(\"../data/map.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (11.48,12.48))\n",
    "ax.scatter(data_to_print.longitude, data_to_print.latitude, zorder=1, alpha= 1, c=color, s=10)\n",
    "ax.set_title('Plotting rating on SF Map')\n",
    "ax.set_xlim(Box[0],Box[1])\n",
    "ax.set_ylim(Box[2],Box[3])\n",
    "ax.imshow(carte, zorder=0, extent = Box, aspect= 'equal')\n",
    "\n",
    "#fig.savefig('testeo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
